Eissen_2002_Analysis of clustering algorithms for web-based search
Karagiannis & Reimer (Eds.): Practical Aspects of Knowledge Management.
 Automatic document categorization plays a key role in the development of future interfaces for Web-based search. Clustering algorithms are considered as a technology that is capable of mastering this “ad-hoc” categorizationtask.This paper presents results of a comprehensive analysis of clustering algorithms in connection with document categorization. The contributions relate toexemplar-based, hierarchical, and density-based clustering algorithms. In particular, we contrast ideal and real clustering settings and present runtime results thatare based on efficient implementations of the investigated algorithms.Key words: Document Categorization, Clustering, Clustering QualityMeasures, Information Retrieval1 Web-based Search and ClusteringThe Internet provides a huge collection of documents, and its use as a source of information is obvious and became very popular. As pointed out and analyzed by Denniset al. there is a plethora of Web search technology, which can broadly be classified intofour categories [4]:(1) Unassisted Keyword Search. One or more search terms are entered and the searchengine returns a ranked list of document summaries. Representatives: Google(www.google.com) or AltaVista (www.altavista.com).(2) Assisted Keyword Search. The search engine produces suggestions based on theuser’s initial query. Representative: Vivisimo (www.vivisimo.com).(3) Directory-based Search. Here, the information space is divided into a hierarchy ofcategories, where the user navigates from broad to specific classes. Representative:Yahoo! (www.yahoo.com).(4) Query-by-Example. The user selects an interesting document snippet, which is thenused as the basis of a new query.In our working group we concentrate on developing smart interfaces for Webbased search. We think that the ideal search interface should model the search processwithin three phases: (a) An initialization phase according to the plain unassisted keyword search paradigm, (b) a categorization phase similar to the directory-based searchAnalysis of Clustering Algorithms for Web-based Search169paradigm, and (c) a refinement phase that may combine aspects from assisted keywordsearch and the query-by-example paradigm. Our realization of this process pursues ameta search strategy similar to that of Vivisimo; i. e., it employs existing search technology within the initialization phase.The outlined ideal search process is the result of the following observations:Existing search engines do an excellent and convenient job. They organize up to billions of documents which can be searched quickly for keywords, and, the plain keywordsearch forms the starting point for the majority of users. However, while this strategyworks fine for the experienced human information miner, the typical user is faced either with an empty result list or with a list containing thousands of hits. The formersituation is the result of misspelling or contradictory Boolean query formulation; it canbe addressed with a syntactic analysis. The latter situation lacks a meaningful specification of context—it requires a semantic analysis, which can be provided by means ofcategory narrowing. In this connection some search engines use a human-maintainedpredefined topic hierarchy with about 20 top-level categories like sports, art, music etc.Such static hierarchies are unsatisfactory within two respects: They require a considerable human maintenance effort, and, for special topics (example: “sound card driver”)the categories constitute an unnecessary browsing overhead which defers the searchprocess. A powerful focusing assistance must be based onto a query-specific—say: adhoc—categorization of the delivered documents.1.1 Contributions of the PaperThis paper focuses on ad-hoc categorization. Ad-hoc categorization comes along withtwo major challenges: Efficiency and nescience. Efficiency means that category formation must be performed at minimum detention, while nescience means that the categoryformation process is unsupervised: Except for experimental evaluation purposes, nopredefined categorization scheme is given from which classification knowledge can beacquainted.The paper in hand provides results of an analysis of clustering algorithms in connection with automatic document categorization. In particular, our contributions arethreefold:(1) The categorization performance of exemplar-based, hierarchical, and density-basedclustering algorithms is shown within an idealized scenario. Such a scenario ischaracterized by the fact that no parameters of the clustering algorithm need tobe estimated but the optimum values are chosen by a global analysis.(2) In a realistic scenario, internal clustering quality measures are necessary to estimatecluster numbers, agglomeration thresholds, or neighborhood densities. From thevarious number of internal measures we have chosen approved ones and analyzethe degradation of categorization performance compared to the optimum values.(3) Several runtime issues are presented. They relate to both the algorithmic propertiesof the investigated algorithms and the difference when switching from an idealizedto a realistic scenario.Altogether, our analysis shall help to answer the question whether the investigatedclustering technology is suited to master the pretentious job of ad-hoc categorization.170Meyer zu Eissen and Stein2 Document Representation, Clustering, and Quality MeasuresThe statistical method of variance analysis is used to verify whether a classificationof given objects by means of nominal features is reflected in significant differencesof depending metric features. Clustering can be considered as some kind of inverseoperation: It tries to identify groups within an object set such that elements of differentgroups show significant differences with respect to their metric features.Clustering algorithms operate on object similarities, which, in turn, are computedfrom abstract descriptions of the objects. Each such description is a vector d of numberscomprising values of essential object features. This section outlines the necessary concepts in connection with text documents: A suited object description, a related similarity measure, an overview of clustering algorithms, and—in particular, clustering qualitymeasures for the analysis of an algorithm’s categorization performance.2.1 Document RepresentationA common representation model for documents is the vector space model, where eachdocument is represented in the term space, which roughly corresponds to the union ofthe m words that occur in a document collection [17, 11]. In this term space, commonwords are filtered out by means of a stop word list, words that are unique in the collection are omitted, and stemming is applied to reduce words towards a canonical form.The document collection D = {d 1 , . . . , dn } can then be described by means of vectors dj = (wj1 , . . . , wjm ), where wji designates a weight of term t i in document d j .Widely accepted variants for the choice of w ji are the following.(1) The term frequency tf (d j , ti ) denotes the frequency of term i in document j. Defining the weights wji as tf (dj , ti ) implies that terms that are used more frequentlyare rated more important.(2) The inverse document frequency is defined as idf (t i ) := log( df n(ti ) ), where nis the total number of documents in the collection and df (t i ) is the numberof documents which contain the term t i . The hypothesis is that terms that occur rarely in a document collection are of highly discriminative power. Definingwji := tf (dj , ti ) · idf (ti ) combines the hypothesis with Point (1) and has shownto improve the retrieval performance [20]. Note that the representation of a singledocument requires knowledge of the whole collection if idf is used.2.2 Document SimilarityClustering exploits knowledge about the similarity among the objects to be clustered.The similarity ϕ of two documents, d 1 , d2 , is computed as a function of the distancebetween the corresponding term vectors d 1 and d2 . There exist various measures forsimilarity computation, from which the cosine-measure proved to be the most successful for document comparison. It is defined as follows.ϕ(d1 , d2 ) =d1 , d2 ,||d1 || · ||d2 ||Analysis of Clustering Algorithms for Web-based Search171where d1 , d2  = dT1 d2 denotes the scalar product, and ||d|| the Euclidean length. Itcalculates the cosine of the angle between two documents in R m . Note that a distancemeasure can easily be derived from ϕ by subtracting the similarity value from 1.2.3 Clustering AlgorithmsLet D be a set of objects. A clustering C = {C | C ⊆ D} of D is a division of Dinto sets for which the following conditions hold: Ci ∈C Ci = D, and ∀Ci , Cj ∈ C :Ci ∩ Cj=i = ∅.Clustering algorithms, which generate a clustering C, are distinguished with respectto their algorithmic properties. The following overview cannot be complete but outlinesthe most important classes along with the worst-case runtime behavior of prominentrepresentatives. Again, n designates the number of documents in a given collection.Iterative Algorithms. Iterative algorithms strive for a successive improvement of an existing clustering and can be further classified into exemplar-based and commutationbased approaches. These approaches need information with regard to the expectedcluster number, k. Representatives: k-Means, k-Medoid, Kohonen, Fuzzy-k-Means[15, 9, 10, 24]. The runtime of these methods is O(nkl), where l designates the numberof necessary iterations to achieve convergence.Hierarchical Algorithms. Hierarchical algorithms create a tree of node subsets by successively merging (agglomerative approach) or subdividing (divisive approach) the objects. In order to obtain a unique clustering, a second step is necessary that prunes thistree at adequate places. Representatives: k-nearest-neighbor, linkage, Ward, or Mincut methods [6, 21, 7, 13, 23]. Usually, these methods construct a complete similaritygraph, which results in O(n 2 ) runtime.Density-based Algorithms. Density-based algorithms try to separate a similarity graphinto subgraphs of high connectivity values. In the ideal case they can determine thecluster number k automatically and detect clusters of arbitrary shape and size. Representatives: D BSCAN, M AJOR C LUST, C HAMELEON [22, 5, 8]. The runtime of thesealgorithms cannot be stated uniquely since it depends on diverse constraints. Typically,it is in magnitude of hierarchical algorithms, O(n 2 ), or higher.Meta-Search Algorithms. Meta-search algorithms treat clustering as an optimizationproblem where a given goal criterion is to be minimized or maximized [1, 18, 19, 18].Though this approach offers maximum flexibility, only less can be stated respecting itsruntime.2.4 Clustering Quality MeasuresMany clustering algorithms do not return a definite clustering but a set of clusteringsfrom which the best one has to be chosen. In particular, uniqueness within exemplarbased algorithms requires information about the cluster number, uniqueness within hierarchical algorithms requires an agglomeration threshold, or, within density-based algorithms, uniqueness requires a threshold for interpreting the neighborhood graph. Ifwe had a measure to assess the quality of a clustering, the ambiguity could be mastered172Meyer zu Eissen and Steinby simply computing several candidate clusterings and choosing the best one with respect to that measure. Note, however, that this is not a runtime problem in first place,but a problem of defining a suited quality measure.Clustering quality measures evaluate the validity of a clustering and can be groupedinto two categories: external and internal 1 . The following paragraphs introduce twoclustering quality measures that are used within our experiments.External Measures. External clustering quality measures use statistical tests to quantify how well a clustering matches the underlying structure of the data. In our context,the underlying structure is the known categorization of a document collection D as provided by a human editor. A broadly accepted external measure is the F -Measure, whichcombines the precision and recall ideas from information retrieval [12].Let D represent the set of documents and let C = {C 1 , . . . , Ck } be a clusteringof D. Moreover, let C ∗ = {C1∗ , . . . , Cl∗ } designate the human reference classification.Then the recall of cluster j with respect to class i, r ec(i, j), is defined as |C j ∩Ci∗ |/|Ci∗ |.The precision of cluster j with respect to class i, prec(i, j), is defined as |C j ∩Ci∗ |/|Cj |.The F -Measure combines both values as follows:Fi,j =2 · prec(i, j) · r ec(i, j)prec(i, j) + r ec(i, j)Based on this formula, the overall F -Measure of a clustering is:F =l|C ∗ |ii=1|V |· max {Fi,j }j=1,...,kA perfect clustering matches the given categories exactly and leads to an F -Measurevalue of 1.Internal Measures. In absence of an external judgment, internal clustering quality measures must be used to quantify the validity of a clustering. Bezdek et al. present a thorough analysis of several internal measures, and, in this paper we rely on a measure fromthe Dunn Index family, which came off well in Bezdek et al.’s experiments [3, 2].Let C = {C1 , . . . , Ck } be a clustering, δ : C × C → R +0 be a cluster-to-clusterbeaclusterdiametermeasure.Then all measuresdistance measure, and ∆ : C → R +0d : C → R+oftheform0d(C) =mini=j {δ(Ci , Cj )}max1≤l≤k {∆(Cl )}are called Dunn Indices. Of course there are numerous choices for δ and ∆, and Bezdeket al. experienced that the combination of
